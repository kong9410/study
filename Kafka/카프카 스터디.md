# 카프카

> 분산 스트리밍 플랫폼 (distribute streaming platform)

기존 API Call의 방식은 Client가 API 서버에 요청을 하면 API가 그것에 맞는 응답을 해주는 형식, 카프카는 이런 방식이 아닌 데이터를 미리 보관해두고 그것을 꺼내쓰는 방식임.

client는 어느 api에 요청을 할지 알고 있어야하지만 카프카를 이용하면 알 필요가 없이 그냥 kafka에서 데이터를 꺼내와서 사용.

## 발행 구독 모델 (PUB/SUB SYSTEM MODEL)

구성 요소 : Publisher, Pub/Sub System, Subscriber

그림

Publisher가 데이터를 P/S에 담고, Subscriber가 꺼내쓰는 방식

Rebbit MQ, Active MQ 같은 메시징 queue를 쓰는 방식이 있는데, 이것은 서버 1대에 데이터 유실, 순서 등을 보장하지만 많은 데이터가 큐에 쌓이면 병목현상이 일어날 수가 있음 카프카에 비해 처리 속도가 느림

카프카는 broker라는 여러대의 서버를 두어 각 서버 토픽별로 queue를 쌓아둘 수가 있음



## 카프카 구조

그림

Producer -> Kafka Cluster [Broker] -> Cunsumer Group [Consumer]





Message

- 카프카에서 데이터 단위, 큐에 저장되는 토픽의 최소 단위
- Header + Value
- Header에는 Key가 포함되어 있음
- Key를 이용해 Partition 결정
- 메시지는 한건씩 보내는 것이 아닌 Batch 단위로 보냄

Topic

- 하나의 파티션
- 큐로 구성되어 있음
- 데이터를 주제별로 묶어 놓은것임
- 여러 Broker에 Topic이 나누어져 있음
- 원하는대로 늘릴 수는 있지만 줄이지는 못함
- 큐 구조이기 때문에 FIFO 이지만 실제로 메시지가 없어지는 것은 아님
- 각 Consumer별로 큐의 끝을 가리키는 포인터만 변동됨

Batch

- Publisher에서 Kafka로 보내는 메시지량을 정함
- 메시지가 일정량 이상 쌓이면 전송할 수 있게 하는 것
- 사이즈를 잘 정해야함
- 가령 100kb가 평균 메시지이고, Batch 사이즈가 500MB라고 하면, 메시지 전송 시간이 너무 길어지기 때문에 적절한 크기로 지정해야함



## Ownership

한 파티션은 Consumer Group별로 하나의 Consumer를 가짐

한 Consumer는 여러개의 파티션을 가질 수 있음



## Offset Commit

메시지가 유실되는 것을 방지하기 위해 사용, Consumer측에서 서버가 꺼졌을 경우 중단된 지점부터 다시 요청 할 수 있게 하기 위함, 단 commit이 제대로 일어나지 않았을 경우엔 데이터 유실이 발생할 수 있음. 또한 메시지 중복처리의 가능성도 존재

Consumer는 Ownership을 갖는 파티션으로 부터 메시지를 받음

Consumer는 Offset Commit 이라는 메시지를 보냄 (예: 1부터 10까지 받았으면 Offset Commit 10)

파티션에서 다음 메시지를 보냄



## Replica

Consumer나 Publisher에서는 Leader가 되는 파티션만 바라보고 있음. 만약에 Broker가 다운되거나 파티션 하나가 죽으면 새로운 파티션을 선정해야함. 때문에 기존의 파티션의 정보를 가지고 있는 레플리카가 필요하며 이 레플리카는 리더로 지정되어 있는 파티션을 Consume 하게됨. 각 레플리카는 Broker 별로 골고루 분산되어 Consume하고 새로운 Leader 파티션을 정해야 한다면 Leader와 동기화되어 있는 Partition을 찾고, 그것을 Leader 파티션으로 정함.

ISP



## 환경

- cpu : 압축을 하지 않는 이상 많이 점유하지는 않음
- memory : 많으면 많을 수록 좋음
- disk : RAID

APP  |  OS  |  Physic

​     =>  RAM <= LAN <=>

​                     ^      V

​                     ㄴ HDD



## Broker가 데이터를 저장하는 방식

한 파티션은 하나의 log 디렉터리를 생성하고 내부에 여러개의 Segment가 생긴다

`~/log/segment...`

## Kafka 설정

- broker.id

  - Default: 0

  - 숫자로 이루어져 있음
  - 중복이 되면 안됨

- port

  - 기본 포트 9092

- zookeeper.connect

  - ip:port, ip:port

- log.dirs

  - 로그가 저장되는 장소
  - 여러개 설정 가능

- auto.create.topics.enable

  - 토픽 자동 생성

  - Default: true

  - 자동 생성 되는 경우 3가지

    1) 없는 토픽 조회시 생성

    2) Producer에서 없는 Topic 넣었을 경우

    3) 없는 Topic Consume 했을 경우

  - false로 설정 추천

- num.partitions

  - 자동 생성될 때 파티션 갯수
  - Default: 1

- log.retention.ms (hours/minutes)

  - 세그먼트 저장 주기
  - 기본값 7일
  - ms, minutes, hours 우선순위로 단위가 작은 것이 기준이됨

- log.retention.bytes

  - 파일이 일정 크기 이상이면 Segment 하나 삭제

- log.segment.bytes

  - 한 세그먼트를 다 채우고 나면 현재 세그먼트를 닫고, 다음 세그먼트를 연다.
  - 너무 크거나 작으면 문제가 생김

- log.segment.ms

  - 일정 시간이 지나면 저절로 닫힘





